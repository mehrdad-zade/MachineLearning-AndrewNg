Support Vector Regression (SVR) is similar to SVM for classification. The idea is to minimize error, finding the hyperplane which maximizes the margin. In addition, a margin of tolerance (epsilon) is set in approximation to the SVM (we want to make sure errors won't exceed the threshold). If we are looking for y=wX+b,then y-wX-b<epsilon and wX+b-y<epsilon. Epsilon is the perpendicular distance between the hyperplane and the higher (and lower) margin. In this case we are looking for a small w so we should minimize 1/2||w||^2.

This process requires choosing a kernel and regularization. Gaussian is the basic choice. 